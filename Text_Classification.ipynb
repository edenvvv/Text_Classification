{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "data = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)  # Vocabulary\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = data.get_word_index()\n",
    "\n",
    "word_index = {k: (v + 3) for k, v in word_index.items()}  # Sort the wards as a dict\n",
    "# \"(v+3)\" Because of the three special characters\n",
    "word_index[\"<PAD>\"] = 0  # Space\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # UNK == Unknown\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a powerful study of loneliness sexual <UNK> and desperation be patient <UNK> up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to <UNK> a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(val, key) for (key, val) in word_index.items()])  # swipe the dictionary\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"], padding=\"post\", maxlen=100)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"], padding=\"post\", maxlen=100)\n",
    "\n",
    "def decode_to_view(text):\n",
    "    \"\"\"\n",
    "    decode to text\n",
    "    :param text:\n",
    "    \"\"\"\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "print(decode_to_view(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))  # number of Neurons\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.5292 - val_loss: 0.6889 - val_accuracy: 0.5997\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6835 - accuracy: 0.6577 - val_loss: 0.6777 - val_accuracy: 0.6975\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6664 - accuracy: 0.7309 - val_loss: 0.6571 - val_accuracy: 0.7361\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.7719 - val_loss: 0.6253 - val_accuracy: 0.7647\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.7945 - val_loss: 0.5848 - val_accuracy: 0.7878\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5492 - accuracy: 0.8182 - val_loss: 0.5403 - val_accuracy: 0.8010\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.8341 - val_loss: 0.4980 - val_accuracy: 0.8124\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.8487 - val_loss: 0.4606 - val_accuracy: 0.8245\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8599 - val_loss: 0.4302 - val_accuracy: 0.8337\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8701 - val_loss: 0.4062 - val_accuracy: 0.8392\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8773 - val_loss: 0.3879 - val_accuracy: 0.8439\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3221 - accuracy: 0.8849 - val_loss: 0.3740 - val_accuracy: 0.8466\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3012 - accuracy: 0.8917 - val_loss: 0.3637 - val_accuracy: 0.8475\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.2829 - accuracy: 0.8981 - val_loss: 0.3555 - val_accuracy: 0.8483\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2669 - accuracy: 0.9038 - val_loss: 0.3498 - val_accuracy: 0.8496\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.9089 - val_loss: 0.3455 - val_accuracy: 0.8500\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2397 - accuracy: 0.9139 - val_loss: 0.3420 - val_accuracy: 0.8492\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2279 - accuracy: 0.9185 - val_loss: 0.3406 - val_accuracy: 0.8496\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2171 - accuracy: 0.9239 - val_loss: 0.3396 - val_accuracy: 0.8493\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9279 - val_loss: 0.3400 - val_accuracy: 0.8500\n",
      "782/782 [==============================] - 0s 602us/step - loss: 0.3490 - accuracy: 0.8445\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "fit_model = model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review: \n",
      "a powerful study of loneliness sexual <UNK> and desperation be patient <UNK> up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to <UNK> a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\n",
      "The predict: [1.]\n",
      "The real: 1\n",
      "[0.3489839434623718, 0.8445199728012085]\n"
     ]
    }
   ],
   "source": [
    "test_review = test_data[1]\n",
    "predict = model.predict([test_review])\n",
    "print(\"The review: \")\n",
    "print(decode_to_view(test_review))\n",
    "print(\"The predict: \" + str(predict[1]))\n",
    "print(\"The real: \" + str(test_labels[1]))\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
